name: Generate Static Predictions

on:
  # Run after new flight data is collected
  workflow_run:
    workflows: ["Daily Flight Data Collection"]
    types:
      - completed
  # Allow manual trigger
  workflow_dispatch:

jobs:
  generate:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Generate static API files
        run: |
          # Create necessary directories
          mkdir -p _site/api/predictions
          mkdir -p _site/api/flights
          
          python -c "
          import json
          import os
          import pandas as pd
          import logging
          from datetime import datetime
          from collections import defaultdict
          from src.models.predictor import BeveragePredictor
          from src.utils.route_utils import calculate_flight_duration
          
          # Set up logging
          logging.basicConfig(level=logging.INFO)
          logger = logging.getLogger(__name__)
          
          # Initialize predictor with saved model
          predictor = BeveragePredictor()
          logger.info('Initialized predictor')
          
          # Process all flight data files
          data_dir = 'data/historical'
          api_dir = '_site/api'
          predictions_dir = os.path.join(api_dir, 'predictions')
          flights_dir = os.path.join(api_dir, 'flights')
          
          logger.info(f'Processing files from {data_dir}')
          logger.info(f'Output directories: {predictions_dir}, {flights_dir}')
          
          # Track all dates and flights by date
          all_dates = set()
          flights_by_date = defaultdict(list)
          
          # List all files first
          flight_files = [f for f in os.listdir(data_dir) if f.endswith('_flights.json')]
          logger.info(f'Found {len(flight_files)} flight data files')
          
          for file in flight_files:
              logger.info(f'Processing {file}')
              with open(os.path.join(data_dir, file)) as f:
                  flights = json.load(f)
                  logger.info(f'Found {len(flights)} flights in {file}')
                  
                  for flight in flights:
                      # Extract flight details
                      flight_number = flight['callsign'].replace('SWA', '')
                      origin = flight['estDepartureAirport']
                      destination = flight['estArrivalAirport']
                      timestamp = flight['firstSeen']
                      departure_time = datetime.fromtimestamp(timestamp).isoformat()
                      date = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
                      
                      logger.info(f'Processing flight {flight_number} on {date}')
                      
                      # Add to dates set
                      all_dates.add(date)
                      
                      # Create flight object
                      flight_obj = {
                          'flight_number': flight_number,
                          'departure_time': departure_time,
                          'origin': origin,
                          'destination': destination,
                          'passenger_count': 150  # Default for now
                      }
                      
                      # Add to flights by date
                      flights_by_date[date].append(flight_obj)
                      
                      # Create prediction input
                      flight_data = pd.DataFrame([{
                          'flight_number': flight_number,
                          'timestamp': timestamp,
                          'duration_hours': calculate_flight_duration(origin, destination),
                          'passenger_count': 150,  # Default for now
                          'origin_airport': origin,
                          'destination_airport': destination
                      }])
                      
                      # Generate predictions
                      predictions = predictor.predict(flight_data)
                      
                      # Format response
                      total_beverages = sum(predictions.values())
                      beverages_per_passenger = round(total_beverages / 150, 1)
                      
                      prediction_data = {
                          'flight_number': flight_number,
                          'departure_time': departure_time,
                          'origin': origin,
                          'destination': destination,
                          'passenger_count': 150,
                          'total_beverages': total_beverages,
                          'beverages_per_passenger': beverages_per_passenger,
                          'flight_duration': calculate_flight_duration(origin, destination),
                          'beverage_predictions': {
                              name: {
                                  'quantity': int(quantity),
                                  'confidence': min(95, max(70, 85 + quantity/10)),
                                  'status': 'optimal' if quantity > 0 else 'critical',
                                  'trend': 'up' if quantity > 100 else 'down' if quantity < 50 else 'stable',
                                  'trend_color': 'success' if quantity > 100 else 'danger' if quantity < 50 else 'secondary'
                              }
                              for name, quantity in predictions.items()
                          }
                      }
                      
                      # Save prediction to file
                      prediction_file = os.path.join(predictions_dir, f'{flight_number}.json')
                      with open(prediction_file, 'w') as f:
                          json.dump(prediction_data, f, indent=2)
                      logger.info(f'Saved prediction to {prediction_file}')
                      
          # Save dates.json
          dates_file = os.path.join(api_dir, 'dates.json')
          with open(dates_file, 'w') as f:
              json.dump({'dates': sorted(list(all_dates))}, f, indent=2)
          logger.info(f'Saved dates to {dates_file}')
          
          # Save flight data by date
          for date, flights in flights_by_date.items():
              flight_file = os.path.join(flights_dir, f'{date}.json')
              with open(flight_file, 'w') as f:
                  json.dump({'flights': sorted(flights, key=lambda x: x['departure_time'])}, f, indent=2)
              logger.info(f'Saved flights for {date} to {flight_file}')
              
          # List all generated files
          logger.info('\nGenerated files:')
          for root, dirs, files in os.walk('_site'):
              for file in files:
                  logger.info(os.path.join(root, file))
          "
          
      - name: List generated files
        run: |
          echo "Generated files:"
          find _site -type f
          
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./_site
          keep_files: true  # Keep other static files 